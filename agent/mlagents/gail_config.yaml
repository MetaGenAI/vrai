default:
    trainer: ppo
    batch_size: 1024
    beta: 5.0e-3
    buffer_size: 10240
    epsilon: 0.2
    hidden_units: 128
    lambd: 0.95
    learning_rate: 3.0e-4
    max_steps: 5.0e7
    memory_size: 256
    normalize: false
    num_epoch: 3
    num_layers: 2
    time_horizon: 64
    sequence_length: 64
    summary_freq: 10000
    use_recurrent: false
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99

NeosAgent3:
    summary_freq: 3000
    time_horizon: 128
    batch_size: 128
    buffer_size: 2048
    hidden_units: 512
    num_layers: 2
    beta: 1.0e-2
    max_steps: 1.0e7
    num_epoch: 3
    behavioral_cloning:
        demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\test2.demo
        strength: 0.5
        steps: 150000
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        curiosity:
            strength: 0.02
            gamma: 0.99
            encoding_size: 256
        gail:
            strength: 0.01
            gamma: 0.99
            encoding_size: 128
            demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\test2.demo

CrawlerStatic:
    normalize: true
    num_epoch: 3
    time_horizon: 1000
    batch_size: 2024
    buffer_size: 20240
    max_steps: 1e7
    summary_freq: 30000
    num_layers: 3
    hidden_units: 512
    behavioral_cloning:
        demo_path: Project/Assets/ML-Agents/Examples/Crawler/Demos/ExpertCrawlerSta.demo
        strength: 0.5
        steps: 50000
    reward_signals:
        gail:
            strength: 1.0
            gamma: 0.99
            encoding_size: 128
            demo_path: Project/Assets/ML-Agents/Examples/Crawler/Demos/ExpertCrawlerSta.demo

NeosAgent:
    max_steps: 1.0e10
    batch_size: 200
    buffer_size: 1000
    lambd: 0.95
    epsilon: 0.21
    num_epoch: 5
    learning_rate: 5.0e-4
    time_horizon: 64
    beta: 1.0e-1
    hidden_units: 512
    summary_freq: 1000
    num_layers: 2
    use_recurrent: false
    sequence_length: 4
    vis_encode_type: resnet
    learning_rate_schedule: linear
    behavioral_cloning:
        demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\virustestfixed2.demo
        strength: 0.3
        steps: 10000
        batch_size: 32
    reward_signals:
        gail:
            strength: 1.0
            gamma: 0.95
            use_actions: false
            use_vail: false
            encoding_size: 128
            demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\virustestfixed2.demo
            learning_rate: 1.0e-4

NeosAgent1:
    max_steps: 1.0e10
    batch_size: 200
    buffer_size: 1000
    lambd: 0.95
    epsilon: 0.21
    num_epoch: 5
    learning_rate: 5.0e-4
    time_horizon: 512
    beta: 1.0e-2
    hidden_units: 512
    summary_freq: 1000
    num_layers: 2
    use_recurrent: false
    sequence_length: 4
    behavioral_cloning:
        demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\virustestfixed2.demo
        strength: 0.90
        steps: 15000
    vis_encode_type: simple
    reward_signals:
        gail:
            strength: 0.95
            gamma: 0.95
            use_actions: true
            use_vail: false
            encoding_size: 128
            demo_path: ..\..\environment\neos\UnityMiddleWare2\Assets\Demonstrations\virustestfixed2.demo

Hallway:
    use_recurrent: true
    sequence_length: 64
    num_layers: 2
    hidden_units: 128
    memory_size: 256
    beta: 1.0e-2
    num_epoch: 3
    buffer_size: 1024
    batch_size: 128
    max_steps: 1.0e7
    summary_freq: 10000
    time_horizon: 64
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        gail:
            strength: 0.1
            gamma: 0.99
            encoding_size: 128
            demo_path: Project/Assets/ML-Agents/Examples/Hallway/Demos/ExpertHallway.demo

FoodCollector:
    batch_size: 64
    max_steps: 2.0e6
    use_recurrent: false
    hidden_units: 128
    learning_rate: 3.0e-4
    num_layers: 2
    sequence_length: 32
    reward_signals:
        gail:
            strength: 0.1
            gamma: 0.99
            encoding_size: 128
            demo_path: Project/Assets/ML-Agents/Examples/FoodCollector/Demos/ExpertFood.demo
    behavioral_cloning:
        demo_path: Project/Assets/ML-Agents/Examples/FoodCollector/Demos/ExpertFood.demo
        strength: 1.0
        steps: 0

GridWorld1:
    batch_size: 64
    max_steps: 2.0e6
    use_recurrent: false
    hidden_units: 128
    learning_rate: 3.0e-4
    num_layers: 2
    sequence_length: 32
    reward_signals:
        gail:
            strength: 0.1
            gamma: 0.99
            encoding_size: 128
            demo_path: "C:/Users/Guillermo Valle/code/ml-agents-latest_release/Project/Assets/Demonstrations/testdemo.demo"
    behavioral_cloning:
        demo_path: "C:/Users/Guillermo Valle/code/ml-agents-latest_release/Project/Assets/Demonstrations/testdemo.demo"
        strength: 1.0
        steps: 0

GridWorld:
    max_steps: 1.0e10
    batch_size: 200
    buffer_size: 1000
    lambd: 0.95
    epsilon: 0.21
    num_epoch: 5
    learning_rate: 5.0e-4
    time_horizon: 64
    beta: 1.0e-1
    hidden_units: 512
    summary_freq: 1000
    num_layers: 2
    use_recurrent: false
    sequence_length: 4
    vis_encode_type: resnet
    learning_rate_schedule: linear
    behavioral_cloning:
        demo_path: "C:/Users/Guillermo Valle/code/ml-agents-latest_release/Project/Assets/Demonstrations/testdemo.demo"
        strength: 0.3
        steps: 10000
        batch_size: 32
    reward_signals:
        gail:
            strength: 1.0
            gamma: 0.95
            use_actions: false
            use_vail: false
            encoding_size: 128
            demo_path: "C:/Users/Guillermo Valle/code/ml-agents-latest_release/Project/Assets/Demonstrations/testdemo.demo"
            learning_rate: 1.0e-4